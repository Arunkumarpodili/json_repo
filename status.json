import json
import os
import sys
from datetime import datetime
from typing import Dict, Optional, List, Set
import concurrent.futures
import requests
from flask import Flask, jsonify
from dotenv import load_dotenv
try:
    from zoneinfo import ZoneInfo
except ImportError:
    from backports.zoneinfo import ZoneInfo

# Load environment variables from .env file
load_dotenv()

app = Flask(__name__)
DATA_FILE = os.path.join(os.path.dirname(__file__), 'health_status.json')
ENDPOINTS_FILE = os.path.join(os.path.dirname(__file__), 'endpoints.json')

BASE_URL = os.getenv('BASE_URL')
AZURE_TENANT_ID = os.getenv('AZURE_TENANT_ID')
AZURE_CLIENT_ID = os.getenv('AZURE_CLIENT_ID')
AZURE_CLIENT_SECRET = os.getenv('AZURE_CLIENT_SECRET')
AZURE_SCOPE = os.getenv('AZURE_SCOPE')
# AZURE_URL = os.getenv('AZURE_URL')
APP_URL = os.getenv('APP_URL')
EXCLUDED_TOOLKITS: Set[str] = {
    "aictgtk-1",
    "air-search-dev",
    "air-tools-dev",
    "architecture-agent",
    "buit-drift-detection-tool",
    "captain-mcp-1-toolkit",
    "captain-mcp-python-toolkit",
    "captain-mcp-test-toolkit",
    "chem-agents-prodtest",
    "cloud-chat-toolkit",
    "cortex-agent-namit-dev",
    "cortex-agents-hta",
    "cortex-alphavantagetool-biswa-dev",
    "cortex-alphavantagetool-test",
    "cortex-alphavantagetoolkit",
    "cortex-guard-insights",
    "cortex-jira-agent-toolkit-g",
    "cortex-text-comparator-5",
    "cortex-text-comparator-6",
    "cortex-text-translation-tool-dev",
    "cortex-urlfetcher",
    "data-analysis-sarita-dev3",
    "dc-ea-agentic-veeva-updatemetadata",
    "dc-ea-agentic-veeva-updatemetadata-tool",
    "dc-ea-agentic-veeva-updatemetadata-toolkit",
    "dd-workshop-github-code-tool",
    "email-tool",
    "ewi-genai-agentic-flow-poc",
    "hangar-support-toolkit",
    "mad-demo1",
    "manasa-toolkit",
    "metadata-extractor-toolkit",
    "metadata-extractor-toolkit-cortex",
    "notifications-toolkit-qa",
    "pharma-rag-toolchain",
    "phi-scrubber",
    "post-conversation-tool",
    "random-number-gen",
    "service-now-toolkit-dev",
    "single-agent-test",
    "spe-captain-test-toolkit",
    "spe-synthetic-agent-toolkit",
    "streetview-dev",
    "test-toolkit-new1",
    "text-compare",
    "text-compare-1",
    "toolkitconfig-4",
    "url-fetcher",
    "notifications-toolkit-dev",
    "dc-ea-veeva-quality-doc-toolkit-dev"
}
AGENT_IDENTIFIERS = {
    "air-deep-research-agent-prd",
    "ethicsandcompliance",
    "spesupportassistant-beta"
}
# Scheduling flags
RUN_AGENTS_30M = "--agents-30m" in sys.argv
RUN_UPLOADS_1H = "--uploads-1h" in sys.argv

# Function to get Microsoft Bearer Token
def get_bearer_token():
    try:
        response = requests.post(
            f"https://login.microsoftonline.com/{AZURE_TENANT_ID}/oauth2/v2.0/token",
            data={
                "client_id": AZURE_CLIENT_ID,
                "client_secret": AZURE_CLIENT_SECRET,
                "scope": AZURE_SCOPE,
                "grant_type": "client_credentials"
            },
            headers={"Content-Type": "application/x-www-form-urlencoded"}
        )
        response.raise_for_status()
        return response.json().get("access_token")
    except requests.exceptions.RequestException as e:
        print(f"Error fetching Microsoft token: {e}")
        return None

# Create and configure requests session
def create_requests_session():
    session = requests.Session()
    token = get_bearer_token()
    # cookie = f"AWSELBAuthSessionCookie-0={os.getenv('LillyCookie')}; AWSELBAuthSessionCookie-1={os.getenv('MicrosoftCookie')}"
    if token:
        session.headers.update({"Authorization": f"Bearer {token}"})
    # session.headers.update({"Cookie": cookie})

    session.verify = True
    session.mount('https://', requests.adapters.HTTPAdapter(
        pool_connections=25,
        pool_maxsize=50,
        max_retries=3,
        pool_block=True
    ))
    return session

# Load and preprocess endpoints from JSON file
def load_endpoints():
    try:
        with open(ENDPOINTS_FILE, 'r') as file:
            endpoints = json.load(file)

        # Replace placeholders like ${BASE_URL} in the loaded JSON
        def replace_placeholders(obj):
            if isinstance(obj, dict):
                return {k: replace_placeholders(v) for k, v in obj.items()}
            elif isinstance(obj, list):
                return [replace_placeholders(item) for item in obj]
            elif isinstance(obj, str):
                return obj.replace("${BASE_URL}", BASE_URL)
            return obj

        return replace_placeholders(endpoints)

    except Exception as e:
        print(f"Error reading endpoints file: {e}")
        return {}

# Replace APIM URL with Cortex App URL
def replace_base_url(data):
    if isinstance(data, dict):
        return {
           replace_base_url(key): replace_base_url(value) for key, value in data.items()
            }
    elif isinstance(data, list):
        return [replace_base_url(item) for item in data]
    elif isinstance(data, str) and BASE_URL in data:
        return data.replace(BASE_URL, APP_URL)
    return data

# Write health status to JSON file
def write_status_data(data):
    try:

        with open(DATA_FILE, 'w') as file:
            json.dump(data, file, indent=2)
    except Exception as e:
        print(f"Error saving to local file: {e}")

def is_first_deployment() -> bool:
    if not os.path.exists(DATA_FILE):
        return True

    try:
        with open(DATA_FILE, "r") as f:
            data = json.load(f)
    except Exception:
        return True

    status = data.get("status", {})

    # If ANY of these sections are missing → first deployment
    required_sections = {
        "agents",
        "toolkits",
        "amazon",
        "openai",
        "anthropic",
        "meta",
        "vertex ai"
    }

    return not required_sections.intersection(status.keys())


def check_endpoint(url: str, method: str = 'GET', payload: Optional[dict] = None, session: requests.Session = None, timeout=30, display_name: str = "", model_info: str = "", question: str = "", tokens: str = "", tokens_per_minute: str = ""):
    try:
        start_time = datetime.now()
        is_upload_endpoint = (
            "/data/upload/" in url or
            "/data/upload-text/" in url
        )
        headers = {}
        session = session or requests.Session()

        # Handle POST and PUT requests with payload
        if method in ['POST', 'PUT'] and payload:
            if isinstance(payload, dict) and payload.get('mode') == 'formdata':
                data = {}
                files = {}
                try:
                    for item in payload['formdata']:
                        if item['type'] == 'file':
                            files[item['key']] = open(item['src'], 'rb')
                        else:
                            data[item['key']] = item['value']
                    response = session.request(method, url, headers=headers, files=files, data=data, timeout=timeout)
                finally:
                    for file in files.values():
                        file.close()
            else:
                response = session.request(method, url, headers=headers, json=payload, timeout=timeout)
        elif method == 'GET':
            response = session.get(url, headers=headers, timeout=timeout)
        elif method == 'DELETE':
            response = session.delete(url, headers=headers, timeout=timeout)
        else:
            response = session.request(method, url, headers=headers, timeout=timeout)

        # Calculate response time
        response_time = (datetime.now() - start_time).total_seconds() * 1000

        # Parse response body
        try:
            response_body = response.json()  # Attempt to parse as JSON
        except ValueError:
            response_body = response.text  # Fall back to plain text if not JSON

        if display_name:
            result = {
                "display_name": display_name,
                "model_info": model_info,
                "question": question,
                "tokens": tokens,
                "tokens_per_minute": tokens_per_minute,
                "url": url,
                "method": method,
                "status": "healthy" if response.status_code == 200 else "unhealthy",
                "code": response.status_code,
                "response_time": int(response_time),
                "error": None,
                "response_body": response_body
            }

            return result

        # --------------- NON-LLM ENDPOINT RETURN ----------------
        return {
            "url": url,
            "method": method,
            "status": "healthy" if response.status_code == 200 else "unhealthy",
            "code": response.status_code,
            "response_time": int(response_time),
            "last_executed_at": datetime.now(ZoneInfo("America/New_York")).isoformat(),
            "error": None,
            "response_body": response_body  # Include the actual response body
        }

    except Exception as e:
        # --------------- LLM/AGENT EXCEPTION RETURN ----------------
        if display_name:
            return {
                "display_name": display_name,
                "model_info": model_info,
                "question": question,
                "url": url,
                "method": method,
                "status": "error",
                "code": None,
                "response_time": None,
                "error": str(e),
                "response_body": None
            }

        # --------------- NON-LLM EXCEPTION RETURN ----------------
        return {
            "url": url,
            "method": method,
            "status": "error",
            "code": None,
            "response_time": None,
            "error": str(e),
            "response_body": None  # Include None if there was an exception
        }

def execute_tool(session, toolkit_name: str, tool_name: str, query="hello"):
    url = (
        f"{BASE_URL}/toolkits/{toolkit_name}/execute"
        f"?tool={tool_name}&query={query}"
    )

    start_time = datetime.now()

    try:
        r = session.get(url, timeout=30)
        response_time = int((datetime.now() - start_time).total_seconds() * 1000)

        try:
            response_body = r.json()
        except ValueError:
            response_body = r.text

        return {
            "url": url,
            "method": "GET",
            "tool": tool_name,
            "status": "healthy" if r.status_code == 200 else "unhealthy",
            "code": r.status_code,
            "response_time": response_time,
            "error": None if r.status_code == 200 else response_body,
            "response_body": response_body
        }

    except Exception as e:
        response_time = int((datetime.now() - start_time).total_seconds() * 1000)
        return {
            "url": url,
            "method": "GET",
            "tool": tool_name,
            "status": "error",
            "code": None,
            "response_time": response_time,
            "error": str(e),
            "response_body": None
        }


def fetch_toolkits_details(session):
    toolkit_status = {}

    # 1) Fetch toolkits list
    try:
        resp = session.get(f"{BASE_URL}/toolkits", timeout=30)
        resp.raise_for_status()
        toolkits_list = resp.json()
    except Exception as e:
        return {
            "toolkits": {
                "error_fetching_toolkits": {
                    "GET": {
                        "status": "error",
                        "code": None,
                        "response_time": None,
                        "error": str(e),
                        "tools": []
                    }
                }
            }
        }


    # 2) PROCESS EACH TOOLKIT

    for tk in toolkits_list:
        name = tk.get("name")
        if not name:
            continue

        if name in EXCLUDED_TOOLKITS:
            continue

        toolkit_status.setdefault("toolkits", {})
        toolkit_status["toolkits"].setdefault(name, {})

        # ---------------- DESCRIBE ----------------
        describe_url = f"{BASE_URL}/toolkits/{name}/describe"
        describe_start = datetime.now()

        try:
            r = session.get(describe_url, timeout=30)
            describe_time = int((datetime.now() - describe_start).total_seconds() * 1000)

            tools = []
            if r.status_code == 200:
                body = r.json()

                # FORMAT A: list response
                if isinstance(body, list):
                    tools = [
                        item.get("name")
                        for item in body
                        if isinstance(item, dict) and "name" in item
                    ]

                # FORMAT B: dict with tools
                elif isinstance(body, dict) and isinstance(body.get("tools"), list):
                    tools = [
                        item.get("name")
                        for item in body["tools"]
                        if isinstance(item, dict) and "name" in item
                    ]

            toolkit_status["toolkits"][name][describe_url] = {
                "GET": {
                    "status": "healthy" if r.status_code == 200 else "unhealthy",
                    "code": r.status_code,
                    "response_time": describe_time,
                    "error": None if r.status_code == 200 else r.text,
                    "tools": tools
                }
            }

        except Exception as e:
            toolkit_status["toolkits"][name][describe_url] = {
                "GET": {
                    "status": "error",
                    "code": None,
                    "response_time": None,
                    "error": str(e),
                    "tools": []
                }
            }
            toolkit_status["toolkits"][name]["status"] = "unhealthy"
            continue

        # 3) PARALLEL EXECUTION OF TOOLS (HEALTH CHECK)

        executions = {}

        def run_tool(tool_name):
            exec_url = (
                f"{BASE_URL}/toolkits/{name}/execute"
                f"?tool={tool_name}&query=hello"
            )

            start = datetime.now()
            try:
                er = session.get(exec_url, timeout=30)
                exec_time = int((datetime.now() - start).total_seconds() * 1000)

                try:
                    exec_body = er.json()
                except ValueError:
                    exec_body = er.text

                return tool_name, {
                    "GET": {
                        "url": exec_url,
                        "method": "GET",
                        "status": "healthy" if er.status_code == 200 else "unhealthy",
                        "code": er.status_code,
                        "response_time": exec_time,
                        "error": None if er.status_code == 200 else exec_body,
                        "response_body": exec_body
                    }
                }

            except Exception as ex:
                exec_time = int((datetime.now() - start).total_seconds() * 1000)
                return tool_name, {
                    "GET": {
                        "url": exec_url,
                        "method": "GET",
                        "status": "error",
                        "code": None,
                        "response_time": exec_time,
                        "error": str(ex),
                        "response_body": None
                    }
                }
        # Disabled toolkit /execute calls as they are causing excessive 500 errors.

        # if tools:
        #     with concurrent.futures.ThreadPoolExecutor(
        #         max_workers=min(10, len(tools))
        #     ) as executor:
        #         futures = [executor.submit(run_tool, t) for t in tools]

        #         for future in concurrent.futures.as_completed(futures):
        #             tool_name, result = future.result()
        #             executions[tool_name] = result

        # toolkit_status["toolkits"][name]["executions"] = executions

        # 4) TOOLKIT OVERALL STATUS (BASED ON TOOLS)

        toolkit_status["toolkits"][name]["status"] = (
            "healthy"
            if executions and all(
                v["GET"]["status"] == "healthy"
                for v in executions.values()
            )
            else "unhealthy"
        )

    return toolkit_status

# Check endpoints for specified categories or all if none specified
def check_all_endpoints(categories_to_check=None):
    if os.path.exists(DATA_FILE):
        try:
            with open(DATA_FILE, "r") as f:
                status_data = json.load(f)
        except Exception:
            status_data = {"status": {}}
    else:
        status_data = {"status": {}}

    now_est = datetime.now(ZoneInfo("America/New_York")).isoformat()

    # Update global timestamp ONLY for full / service / LLM / toolkit runs
    if not RUN_UPLOADS_1H and not RUN_AGENTS_30M:
        status_data["last_updated"] = now_est


    endpoints = load_endpoints()
    session = create_requests_session()
    FIRST_DEPLOYMENT = is_first_deployment()

    # Filter endpoints by category if specified
    if categories_to_check:
        filtered_endpoints = {k: v for k, v in endpoints.items() if k in categories_to_check}
    else:
        # Exclude CORTEX GUARD category by default for regular checks
        filtered_endpoints = {k: v for k, v in endpoints.items() if k != "CORTEX GUARD"}

    with concurrent.futures.ThreadPoolExecutor(max_workers=25) as executor:
        futures = {}
        for category, category_endpoints in filtered_endpoints.items():
            status_data["status"].setdefault(category, {})
            for endpoint in category_endpoints:
                url = endpoint.get("url", "")

                is_upload_endpoint = (
                    "/data/upload/" in url or
                    "/data/upload-text/" in url
                )
                is_agent_endpoint = category.lower() == "agents"

               # FIRST DEPLOYMENT → RUN EVERYTHING
                if FIRST_DEPLOYMENT and not (RUN_AGENTS_30M or RUN_UPLOADS_1H):
                    should_execute = True

                elif RUN_AGENTS_30M:
                    should_execute = is_agent_endpoint

                elif RUN_UPLOADS_1H:
                    should_execute = is_upload_endpoint

                else:
                    should_execute = not (is_agent_endpoint or is_upload_endpoint)

                if not should_execute:
                    continue

                method = endpoint.get("method", "GET").upper()
                payload = endpoint.get("body", None)
                display_name = endpoint.get("display_name", "")
                model_info = endpoint.get("model_info", "")
                question = endpoint.get("question", "")
                tokens = endpoint.get("tokens", "")
                tokens_per_minute = endpoint.get("tokens_per_minute", "")

                # Pass all parameters including question
                futures[(category, url, method)] = executor.submit(
                    check_endpoint, url, method, payload, session, timeout=30, 
                    display_name=display_name, model_info=model_info, question=question,tokens=tokens,tokens_per_minute=tokens_per_minute
                )

        for (category, url, method), future in futures.items():
            result = future.result()

            # recompute agent check here (CORRECT SCOPE)
            is_agent_endpoint = category.lower() == "agents"

            # stamp ONLY if agent actually executed
            if is_agent_endpoint:
                result["last_executed_at"] = datetime.now(
                    ZoneInfo("America/New_York")
                ).isoformat()

            if url not in status_data["status"][category]:
                status_data["status"][category][url] = {}

            status_data["status"][category][url][method] = result

            # Group by both URL and method in the results
            if url not in status_data["status"][category]:
                status_data["status"][category][url] = {}
            status_data["status"][category][url][method] = result

    if not RUN_AGENTS_30M and not RUN_UPLOADS_1H:
        try:
            toolkit_results = fetch_toolkits_details(session)
            status_data["status"].update(toolkit_results)
        except Exception as e:
            print("Error fetching toolkits:", e)     

    return status_data

if __name__ == '__main__':
    status_data = check_all_endpoints()
    write_status_data(status_data)
